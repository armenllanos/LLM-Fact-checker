{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busacador de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from os import path\n",
    "from pathlib import PurePath\n",
    "import concurrent.futures\n",
    "from transformers import pipeline\n",
    "from mistralai import Mistral\n",
    "import pandas as pd\n",
    "import accelerate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import base64\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "from google import genai\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from google.genai import types\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noticia:\n",
    "    def __init__(self, titular: str, url: str, resumen: str):\n",
    "\n",
    "        self.titular = titular\n",
    "        self.url = url\n",
    "        self.resumen = resumen\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de palabras clave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extraer_keywords_yake(texto, idioma=\"es\", max_keywords=5):\n",
    "    extractor = yake.KeywordExtractor(lan=idioma, n=1, top=max_keywords)\n",
    "    keywords = extractor.extract_keywords(texto)\n",
    "    display(keywords)\n",
    "    return [kw for kw, score in keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de noticias en base a las palabras clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_en_theobjective(keywords, max_noticias=5):\n",
    "    query = \"site:theobjective.com \" + \" \".join(keywords)\n",
    "    url = f\"https://html.duckduckgo.com/html/?q={query}\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    resultados = []\n",
    "    print(soup.prettify())\n",
    "    for result in soup.select(\"serp__results\"):\n",
    "        titulo_tag = result.select_one(\"result__title\")\n",
    "        enlace_tag = result.select_one(\"result__a\")\n",
    "        snippet_tag = result.select_one(\"result__snippet\")\n",
    "        \n",
    "        if not (titulo_tag and enlace_tag):\n",
    "            continue\n",
    "\n",
    "        titulo = titulo_tag.text.strip()\n",
    "        enlace = enlace_tag.get(\"href\")\n",
    "        resumen = snippet_tag.text.strip() if snippet_tag else \"\"\n",
    "        \n",
    "        resultados.append({\n",
    "            \"titulo\": titulo,\n",
    "            \"enlace\": enlace,\n",
    "            \"resumen\": resumen\n",
    "        })\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_en_theobjective_ddg(keywords, max_noticias=10):\n",
    "    query = \"site:theobjective.com \" + \" \".join(keywords)\n",
    "    resultados = []\n",
    "    print(query)\n",
    "    with DDGS() as ddgs:\n",
    "        for r in ddgs.text(query, max_results=max_noticias):\n",
    "            resultados.append({\n",
    "                \"titulo\": r[\"title\"],\n",
    "                \"enlace\": r[\"href\"],\n",
    "                \"resumen\": r[\"body\"]\n",
    "            })\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar(keywords):\n",
    "    query = \"site:theobjective.com \" + \" \".join(keywords)\n",
    "    url = f\"https://www.bing.com/search?q={query}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    print(f\"Busqueda en: {url}\")\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    resultados = []\n",
    "    \n",
    "    titulos = soup.find_all('h2')\n",
    "    resumenes = soup.find_all(class_='b_caption')\n",
    "    urls = []\n",
    "    for i in range(0,len(titulos)):\n",
    "        url = titulos[i].find('a')['href']\n",
    "        urls.append(url)\n",
    "    return urls\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_titular_y_resumen(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Estos selectores dependen de la estructura del sitio\n",
    "        titulo = soup.find('h1')\n",
    "        resumen = soup.find('p')\n",
    "\n",
    "        return {\n",
    "            'url': url,\n",
    "            'titulo': titulo.get_text(strip=True) if titulo else 'No encontrado',\n",
    "            'resumen': resumen.get_text(strip=True) if resumen else 'No encontrado',\n",
    "            'contenido':response.text\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'url': url,\n",
    "            'error': str(e)\n",
    "        }\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', np.float64(0.1447773057422032)),\n",
       " ('Donald', np.float64(0.15831692877998726)),\n",
       " ('moviles', np.float64(0.15831692877998726)),\n",
       " ('bajar', np.float64(0.29736558256021506)),\n",
       " ('precio', np.float64(0.29736558256021506))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busqueda en: https://www.bing.com/search?q=site:theobjective.com Trump Donald moviles bajar precio\n",
      "\n",
      "Mejores noticias por similitud\n",
      "\n",
      "Nota 0.7006726861000061\n",
      "\n",
      "Título: Trump defiende sus aranceles y acusa a otros países de «estafar» a EEUU durante décadas\n",
      "\n",
      "Nota 0.6497557759284973\n",
      "\n",
      "Título: Donald Trump dobla la apuesta: 'made in USA' y la amenaza de más aranceles\n",
      "\n",
      "Nota 0.643012285232544\n",
      "\n",
      "Título: Trump usa la economía como los borrachos las farolas: para abrazarse, no para iluminarse\n",
      "\n",
      "Nota 0.5764147043228149\n",
      "\n",
      "Título: Trump sugiere que una bajada en el precio del petróleo terminaría con la guerra en Ucrania\n",
      "\n",
      "Nota 0.48289865255355835\n",
      "\n",
      "Título: El Ibex 35 pierde los 13.100 puntos lastrado por los nuevos aranceles de Donald Trump\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Donald Trump va a bajar el precio de los moviles'\n",
    "keywords = extraer_keywords_yake(user_input)\n",
    "urls = buscar(keywords)\n",
    "\n",
    "resultados = {}\n",
    "for url in urls:\n",
    "    resultados[url] = extraer_titular_y_resumen(url) \n",
    "\n",
    "modelo = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "user_embeddings = modelo.encode([user_input])[0]\n",
    "mejores_noticias = {}\n",
    "for r in resultados.values():\n",
    "    title_embedding = modelo.encode([r['titulo']])[0]\n",
    "    subtitle_embedding = modelo.encode([r['resumen']])[0]\n",
    "    title_score = cosine_similarity([user_embeddings], [title_embedding])[0][0]\n",
    "    subtitle_score = cosine_similarity([user_embeddings], [subtitle_embedding])[0][0]\n",
    "    mean_score = title_score+subtitle_score/2\n",
    "    mejores_noticias[mean_score] = r['url']\n",
    "\n",
    "\n",
    "valoraciones_resumen = sorted(mejores_noticias.keys(),reverse=True)\n",
    "print(\"\\nMejores noticias por similitud\")\n",
    "for i in range(0,5):\n",
    "    print(f\"\\nNota {valoraciones_resumen[i]}\")\n",
    "    url = mejores_noticias[valoraciones_resumen[i]]\n",
    "    print(\"\\nTítulo:\", resultados[url]['titulo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El presidente de\n",
      "Estados Unidos\n",
      ",\n",
      "Donald Trump\n",
      ", ha vuelto a sacar pecho de su política comercial asegurando que los nuevos\n",
      "aranceles\n",
      "anunciados por su Administración son más «generosos» que los que han aplicado durante años otros países contra Washington. Lo ha hecho desde el avión presidencial, en unas declaraciones recogidas por\n",
      "Europa Press\n",
      ", en las que ha insistido en que su Gobierno no está haciendo otra cosa que corregir décadas de desventajas.\n",
      "«Los aranceles son mucho más generosos de lo que esos países han sido con nosotros»\n",
      ", defendió Trump a bordo del\n",
      "Air Force One\n",
      ". «Lo que significa —añadió— que serán más amables de lo que esos países han sido con Estados Unidos durante décadas».\n",
      "El mandatario estadounidense, que ha hecho de\n",
      "la política proteccionista una de sus banderas desde que regresó a la Casa Blanca\n",
      ", arremetió con dureza contra las potencias que mantienen relaciones comerciales con EEUU. «Nos han estafado como nunca se ha estafado a ningún país en la historia, y vamos a ser mucho más amables de lo que ellos fueron con nosotros», subrayó, si bien remarcó que «a pesar de todo, es un dinero sustancial para el país».\n",
      "Trump, harto de Putin: amenaza con aranceles «a todo el petróleo que salga de Rusia»\n",
      "THE OBJECTIVE\n",
      "De esta forma, Trump mantiene su pulso arancelario pese a las advertencias de grandes fabricantes, especialmente del sector del automóvil, sobre el impacto que podrían tener esas medidas en el consumidor estadounidense.\n",
      "Sin ir más lejos, este sábado aseguró en una entrevista con la cadena\n",
      "NBC News\n",
      "que\n",
      "no le preocupa «lo más mínimo» que las automovilísticas suban los precios como consecuencia directa de los aranceles del 25% anunciados para los vehículos importados\n",
      ". «No me importa», zanjó.\n",
      "España, uno de los países más afectados por los aranceles de Trump al petróleo venezolano\n",
      "Víctor Recacha\n",
      "El nuevo giro proteccionista del presidente republicano reaviva la tensión en plena carrera electoral y anticipa un nuevo episodio en la guerra comercial que él mismo reactivó desde su retorno al Despacho Oval.\n"
     ]
    }
   ],
   "source": [
    "clase_noticia = 'div.tno-general-single__article__main__content.tno-single-content'\n",
    "noticia =  resultados[mejores_noticias[valoraciones_resumen[0]]]['contenido']\n",
    "soup = BeautifulSoup(noticia, 'html.parser')\n",
    "# print(soup)\n",
    "contenedor = soup.select_one(clase_noticia)\n",
    "contenido = contenedor.get_text(separator='\\n', strip=True) if contenedor else 'No encontrado'\n",
    "\n",
    "print(contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de embeddings del input del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', np.float64(0.1447773057422032)),\n",
       " ('Donald', np.float64(0.15831692877998726)),\n",
       " ('moviles', np.float64(0.15831692877998726)),\n",
       " ('bajar', np.float64(0.29736558256021506)),\n",
       " ('precio', np.float64(0.29736558256021506))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site:theobjective.com Trump Donald moviles bajar precio\n",
      "Mejores noticias por similitud con el titular\n",
      "\n",
      "Título: España hace guiños a los fabricantes chinos de móviles en plena ...\n",
      "Enlace: https://theobjective.com/economia/telecomunicaciones/2025-03-05/espana-fabricantes-chinos-mobile-eeuu/\n",
      "Resumen: El posicionamiento del Gobierno español frente a China cobra mucha más importancia ahora que Estados Unidos amenaza con elevados aranceles a Europa y que Donald Trump ha incluido al bloque...\n",
      "\n",
      "Título: España se juega 46.000 millones de euros tras la última amenaza de ...\n",
      "Enlace: https://theobjective.com/economia/2025-03-31/trump-46000-millones-espana-aranceles/\n",
      "Resumen: El Ibex 35 pierde los 13.100 puntos lastrado por los nuevos aranceles de Donald Trump\n",
      "\n",
      "Mejores noticias por similitud con el resumen\n",
      "\n",
      "Título: Las consecuencias económicas de Trump para España - THE OBJECTIVE\n",
      "Enlace: https://theobjective.com/economia/2025-02-11/gris-importa-consecuencias-trump-economia-espanola/\n",
      "Resumen: Los números de la economía española son razonablemente buenos. Se mantiene el vigor de la actividad, con un aumento del PIB del 3,2% en 2024. Este buen 'El Gris Importa' analiza el impacto de las...\n",
      "\n",
      "Título: El Ibex 35 pierde los 13.100 puntos lastrado por los nuevos aranceles ...\n",
      "Enlace: https://theobjective.com/economia/2025-03-31/ibex-35-aranceles-donald-trump/\n",
      "Resumen: El Ibex 35 ha perdido este lunes los 13.200 puntos en una jornada marcada por la inquietud de los inversores tras el anuncio del expresidente de Estados Unidos, Donald Trump, sobre nuevos...\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Donald Trump va a bajar el precio de los moviles'\n",
    "modelo = SentenceTransformer('jinaai/jina-embeddings-v3')\n",
    "user_embeddings = modelo.encode([user_input])[0]\n",
    "keywords = extraer_keywords_yake(user_input)\n",
    "\n",
    "\n",
    "#noticias = buscar_en_theobjective(keywords)\n",
    "noticias = buscar_en_theobjective_ddg(keywords)\n",
    "mejores_noticias_titular = {}\n",
    "mejores_noticias_resumen = {}\n",
    "\n",
    "for noticia in noticias:\n",
    "    new_noticia = Noticia(noticia[\"titulo\"],noticia[\"enlace\"],noticia[\"resumen\"])\n",
    "    sentence_embeddings = modelo.encode([noticia[\"titulo\"]])[0]\n",
    "    sim_coseno = cosine_similarity([user_embeddings], [sentence_embeddings])[0][0]\n",
    "    mejores_noticias_titular[sim_coseno] = new_noticia\n",
    "    \n",
    "    sentence_embeddings = modelo.encode([noticia[\"resumen\"]])[0]\n",
    "    sim_coseno = cosine_similarity([user_embeddings], [sentence_embeddings])[0][0]\n",
    "    mejores_noticias_resumen[sim_coseno] = new_noticia\n",
    "\n",
    "valoraciones_titular = sorted(mejores_noticias_titular.keys())\n",
    "print(\"Mejores noticias por similitud con el titular\")\n",
    "for i in range(0,2):\n",
    "    print(\"\\nTítulo:\", mejores_noticias_titular[valoraciones_titular[i]].titular)\n",
    "    print(\"Enlace:\", mejores_noticias_titular[valoraciones_titular[i]].url)\n",
    "    print(\"Resumen:\", mejores_noticias_titular[valoraciones_titular[i]].resumen)\n",
    "\n",
    "valoraciones_resumen = sorted(mejores_noticias_resumen.keys())\n",
    "print(\"\\nMejores noticias por similitud con el resumen\")\n",
    "for i in range(0,2):\n",
    "    print(\"\\nTítulo:\", mejores_noticias_resumen[valoraciones_resumen[i]].titular)\n",
    "    print(\"Enlace:\", mejores_noticias_resumen[valoraciones_resumen[i]].url)\n",
    "    print(\"Resumen:\", mejores_noticias_resumen[valoraciones_resumen[i]].resumen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llamada al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Eres un analista de información riguroso. El usuario te enviará un mensaje con DOS textos separados:  \n",
    "1. El primero es una afirmación o interpretación sobre una noticia.  \n",
    "2. El segundo es la noticia completa (o un fragmento relevante).  \n",
    "\n",
    "Tu tarea es:  \n",
    "1. Comparar la afirmación (texto 1) con el contenido de la noticia (texto 2).  \n",
    "2. Decidir si la afirmación es:  \n",
    "   - **✅ CIERTA**: Si la noticia respalda claramente la afirmación.  \n",
    "   - **❌ FALSA**: Si la noticia contradice directamente la afirmación.  \n",
    "   - **🔎 NO VERIFICABLE**: Si la noticia no contiene información suficiente para validar o refutar la afirmación.  \n",
    "\n",
    "Responde ÚNICAMENTE con una de las 3 opciones (✅ CIERTA, ❌ FALSA, 🔎 NO VERIFICABLE) y añade una explicación breve en la misma línea.  \n",
    "Mantén un tono neutral y objetivo.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"\"\"[Afirmación] :  \"\"\" + user_input +\"\"\" [Noticia]: \"\"\" + contenido\n",
    "messages = [\n",
    "        {   \n",
    "            \"role\":\"system\",\"content\":system_message},\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": user_message\n",
    "        }\n",
    "    ]\n",
    "input_text = f\"<|system|>\\n{system_message}\\n<|user|>\\n{user_message}\\n<|assistant|>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de hugging face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`rope_scaling`'s factor field must be a float >= 1, got 40\n",
      "`rope_scaling`'s beta_fast field must be a float, got 32\n",
      "`rope_scaling`'s beta_slow field must be a float, got 1\n",
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-V3-Base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-V3-Base\"  # o \"deepseek-ai/deepseek-coder-6.7b\" para código\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # Usa GPU automáticamente\n",
    "    torch_dtype=torch.float16  # Reduce uso de memoria (opcional)\n",
    ")\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.3 \n",
    ")\n",
    "\n",
    "respuesta = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(respuesta.split(\"<|assistant|>\")[-1].strip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded an FP8 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-R1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1\", trust_remote_code=True)\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo por API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"sk-d80c8a131e6f464aae72ddc7b48f10b6\"\n",
    "url = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"deepseek-chat\",  # Revisa los modelos disponibles en la documentación\n",
    "    \"messages\":messages\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probar Gemini\n",
    "https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internacional\n",
      "None"
     ]
    }
   ],
   "source": [
    "client = genai.Client(\n",
    "    api_key=\"AIzaSyCaPiJUBW1V2eJ5YUZgJD_RF0R9knWiR2Q\",\n",
    ")\n",
    "\n",
    "model = \"gemma-3-27b-it\"\n",
    "contents = [\n",
    "    types.Content(\n",
    "        role=\"model\",\n",
    "        parts=[\n",
    "            types.Part.from_text(text=\"\"\"Analiza el siguiente texto y determina si trata sobre un tema de índole nacional (relacionado con España) o internacional. Ten en cuenta el contexto, los lugares, instituciones, personajes o eventos mencionados. Devuelve únicamente una de estas dos etiquetas: 'Nacional' o 'Internacional'.\"\"\"),\n",
    "        ],\n",
    "    ),\n",
    "    types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            types.Part.from_text(text=\"\"\"Donald trump se acuesta con putin\"\"\"),\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    max_output_tokens=2000,\n",
    "    response_mime_type=\"text/plain\",\n",
    ")\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=model,\n",
    "    contents=contents,\n",
    "    config=generate_content_config,\n",
    "):\n",
    "    print(chunk.text, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nacional\n"
     ]
    }
   ],
   "source": [
    "api_key = \"uncjhLuimnWfA7S3QJrw7iTWsjYgd2tj\"\n",
    "model = \"mistral-large-latest\"\n",
    "system_promt = \"Analiza el siguiente texto y determina si trata sobre un tema de índole nacional (relacionado con España) o internacional. Ten en cuenta el contexto, los lugares, instituciones, personajes o eventos mencionados. Devuelve únicamente una de estas dos etiquetas: 'Nacional' o 'Internacional'.\"\n",
    "user_prompt =\"El real madrid ha asesinado a vinicius.jr\"\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "chat_response = client.chat.complete(\n",
    "    model= model,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_promt,\n",
    "    },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba modelos distintos propósitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisor de afirmaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-V3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-V3:\n",
      "- configuration_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-V3:\n",
      "- modeling_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "You have loaded an FP8 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear pipeline con un modelo instructivo\n",
    "generator = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-V3\",trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-V3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You have loaded an FP8 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-V3\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-V3\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Texto de entrada\n",
    "text = \"\"\"\n",
    "La inteligencia artificial está transformando el mundo. Se usa en medicina, educación, transporte y finanzas.\n",
    "También plantea desafíos éticos como el sesgo y la pérdida de empleos.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt para dividir en afirmaciones\n",
    "prompt = f\"Divide el siguiente texto en afirmaciones claras, una por línea:\\n\\n{text}\\n\\nAfirmaciones:\"\n",
    "\n",
    "# Generar resultado\n",
    "result = generator(prompt, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "# Mostrar salida\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación nacional/internacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Texto de entrada\n",
    "text = \"\"\"\n",
    "La inteligencia artificial está transformando el mundo. Se usa en medicina, educación, transporte y finanzas.\n",
    "También plantea desafíos éticos como el sesgo y la pérdida de empleos.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt para dividir en afirmaciones\n",
    "prompt = f\"Divide el siguiente texto en afirmaciones claras, una por línea:\\n\\n{text}\\n\\nAfirmaciones:\"\n",
    "\n",
    "# Generar resultado\n",
    "result = generator(prompt, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "# Mostrar salida\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de dataset texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_excel = \"./FakeNewsDetectorSpanish/train.xlsx\"\n",
    "\n",
    "# Leer el archivo Excel\n",
    "df1 = pd.read_excel(ruta_excel)\n",
    "\n",
    "# Verificar que las columnas existen\n",
    "if 'Text' not in df1.columns or 'Category' not in df1.columns:\n",
    "    raise ValueError(\"El archivo debe contener las columnas 'text' y 'category'.\")\n",
    "\n",
    "# Crear el dataset solo con las columnas deseadas\n",
    "df1 = df1[['Text', 'Category']].copy()\n",
    "df1['label'] = df1['Category'].map({'True': 0, 'Fake': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_csv = \"./archive/spanishFakeNews.csv\"\n",
    "df2 = pd.read_csv(ruta_csv)\n",
    "\n",
    "df2.rename(columns={'texto':'Text','clase':'Category'}, inplace=True)\n",
    "df2['label'] = df2['Category'].map({'real': 0, 'fake': 1})\n",
    "ruta_csv = \"./archive/testSpanishFakeNews.csv\"\n",
    "df3 = pd.read_csv(ruta_csv)\n",
    "\n",
    "df3.rename(columns={'texto':'Text','clase':'Category'}, inplace=True)\n",
    "df3['label'] = df2['Category'].map({'real': 0, 'fake': 1})\n",
    "df2 = pd.concat([df2,df3],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset con noticias traducidas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"translated_news_8.csv\"\n",
    "output_file = \"translated_news_mod.csv\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        parts = line.split(\",\", 2)  # divide solo en las dos primeras comas\n",
    "        if len(parts) == 3:\n",
    "            nueva_linea = parts[0] + \";\" + parts[1] + \";\" + parts[2]\n",
    "        else:\n",
    "            nueva_linea = line  # por si acaso no hay dos comas\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"translated_news_mod.csv\"\n",
    "output_file = \"translated_news_8.csv\"\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        partes = line.split(\";\")\n",
    "        if len(partes) > 2:\n",
    "            # Conserva los dos primeros campos con ;\n",
    "            primeros_dos = partes[:2]\n",
    "            resto = partes[2:]\n",
    "            # Une los campos restantes con comas\n",
    "            nueva_linea = \";\".join(primeros_dos) + \";\" + \",\".join(resto)\n",
    "        else:\n",
    "            # Si no hay más de dos campos separados por ;, no se modifica\n",
    "            nueva_linea = line\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('translated_news.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.concat([df,pd.read_csv('translated_news_1.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_2.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_3.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_4.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_5.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_6.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_7.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_8.csv',sep=';')],ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LONDRES (Reuters) - Los legisladores británico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EDINBURGH (Reuters) - Un acuerdo para mantener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17 de noviembre de 2016 - Fort Russ - Antifash...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label Category                                               Text\n",
       "0      0        0  LONDRES (Reuters) - Los legisladores británico...\n",
       "1      0        0  EDINBURGH (Reuters) - Un acuerdo para mantener...\n",
       "2      1        1  17 de noviembre de 2016 - Fort Russ - Antifash..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)\n",
    "df.rename(columns={'Text':'label','label':'Text'},inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarte de que category es de tipo str o int\n",
    "df['Category'] = df['Category'].astype(str)\n",
    "df['label'] = df['label'].astype(int)\n",
    "df.dropna(inplace=True)\n",
    "# Convertir a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:00<00:00, 1931.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'verdadero': 0, 'falso': 1})\n",
    "df['label'] = df['label'].astype(int)\n",
    "df.dropna(inplace=True)\n",
    "# Convertir a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)\n",
    "modelo_nombre = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_nombre)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = tokenized_dataset['label']\n",
    "label_encoder.fit(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1274/1274 [00:01<00:00, 998.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "modelo_nombre = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_nombre)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "all_labels = tokenized_dataset['label']\n",
    "label_encoder.fit(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1019/1019 [00:00<00:00, 8623.88 examples/s]\n",
      "Map: 100%|██████████| 255/255 [00:00<00:00, 7992.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)  # opcional\n",
    "\n",
    "# Ajustar sobre todo el dataset\n",
    "all_labels = tokenized_dataset['train']['Category'] + tokenized_dataset['test']['Category']\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Aplicar a cada parte\n",
    "tokenized_dataset = tokenized_dataset.map(lambda x: {\"label\": label_encoder.transform([x[\"Category\"]])[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traducción de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\",device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./fake_en_dataset/WELFake_Dataset.csv\")  # o el dataset que tengas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'es: mi nombre es miguel'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator('my name is Miguel',src_lang='en',tgt_lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (512). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    }
   ],
   "source": [
    "columnas = ['Text', 'Category', 'label']\n",
    "df_es = pd.DataFrame(columns=columnas)\n",
    "\n",
    "# Traduce por lotes de 10 (recomendado para no saturar la RAM)\n",
    "translated = []\n",
    "with open('translated_news.csv', 'w', encoding='utf-8') as f:\n",
    "    # Escribir la cabecera\n",
    "    f.write(','.join(df_es.columns) + '\\n')\n",
    "f.close()\n",
    "fieldnames = ['Category','label','Text']\n",
    "for index,new in df.iterrows():\n",
    "    try:\n",
    "        results = translator(new['text'], max_length=len(new['text']),src_lang='en',tgt_lang='es')\n",
    "    except:\n",
    "        continue\n",
    "    linea = str(new['label']) + ',' +  str(new['label']) +','+ str(results[0]['translation_text']).replace('es:','')\n",
    "    with open('translated_news.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        csvfile.write(linea + '\\n')\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de análisis semántico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de modelo para elección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* VerificadoProfesional/SaBERT-Spanish-Fake-News\n",
    "* Narrativaai/fake-news-detection-spanish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'Category', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1274\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "nombre = \"Narrativaai/fake-news-detection-spanish\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"modelo_fake_news\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nombre, num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.997157096862793, 'eval_model_preparation_time': 0.0014, 'eval_accuracy': 0.5400313971742543, 'eval_f1': 0.528402773285684, 'eval_runtime': 15.2014, 'eval_samples_per_second': 83.808, 'eval_steps_per_second': 5.263}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=16,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrl\\AppData\\Local\\anaconda3\\envs\\TFM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\mrl\\AppData\\Local\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mrl\\.cache\\huggingface\\hub\\models--VerificadoProfesional--SaBERT-Spanish-Fake-News. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"VerificadoProfesional/SaBERT-Spanish-Fake-News\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrl\\AppData\\Local\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mrl\\.cache\\huggingface\\hub\\models--Narrativaai--fake-news-detection-spanish. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"Narrativaai/fake-news-detection-spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"modelo_fake_news\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Un grupo de pastores gallegos ha descubierto en los montes de Lugo una extraña planta autóctona que, según aseguran, puede cargar teléfonos móviles con solo entrar en contacto con ellos. El hallazgo ha revolucionado a científicos de todo el mundo y ya se habla de una posible “revolución verde” en el campo de la energía renovable.\n",
    "La planta, bautizada popularmente como Electra Verde, fue detectada por primera vez cuando uno de los pastores notó que su viejo móvil, sin batería desde hacía días, se encendió al quedarse apoyado accidentalmente sobre la raíz expuesta de la planta. “Pensé que era cosa de meigas”, declaró entre risas. Pero al repetir el fenómeno varias veces, decidió contactar con expertos de la Universidad de Santiago.\n",
    "Aunque todavía no se ha confirmado nada oficialmente, filtraciones desde el laboratorio apuntan a que Electra Verde podría contener una combinación única de minerales y microalgas que generan corriente eléctrica mediante procesos aún no comprendidos por la ciencia.\n",
    "Mientras tanto, turistas y curiosos ya se agolpan en los montes gallegos, en busca de esta nueva joya botánica que podría hacer obsoletos los cargadores eléctricos en menos de una década.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'FAKE', 'score': 0.999971866607666}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning modelo lingüístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"VerificadoProfesional/SaBERT-Spanish-Fake-News\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modelo, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27348\\1752722915.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7089' max='7089' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7089/7089 1:13:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.127817</td>\n",
       "      <td>0.967305</td>\n",
       "      <td>0.967268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.136887</td>\n",
       "      <td>0.968363</td>\n",
       "      <td>0.968404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.983388</td>\n",
       "      <td>0.983382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7089, training_loss=0.10595419522903525, metrics={'train_runtime': 4425.3995, 'train_samples_per_second': 25.625, 'train_steps_per_second': 1.602, 'total_flos': 2.983758301099008e+16, 'train_loss': 0.10595419522903525, 'epoch': 3.0})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='591' max='591' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [591/591 01:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0846896693110466,\n",
       " 'eval_accuracy': 0.9833880012697069,\n",
       " 'eval_f1': 0.9833821828938577,\n",
       " 'eval_runtime': 109.8881,\n",
       " 'eval_samples_per_second': 86.006,\n",
       " 'eval_steps_per_second': 5.378,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('modelo_fake_news\\\\tokenizer_config.json',\n",
       " 'modelo_fake_news\\\\special_tokens_map.json',\n",
       " 'modelo_fake_news\\\\vocab.txt',\n",
       " 'modelo_fake_news\\\\added_tokens.json',\n",
       " 'modelo_fake_news\\\\tokenizer.json')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"modelo_fake_news\")\n",
    "tokenizer.save_pretrained(\"modelo_fake_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\"text-classification\", model=\"modelo_fake_news\", tokenizer=\"modelo_fake_news\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'False', 'score': 0.9900426864624023}]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Un grupo de pastores gallegos ha descubierto en los montes de Lugo una extraña planta autóctona que, según aseguran, puede cargar teléfonos móviles con solo entrar en contacto con ellos. El hallazgo ha revolucionado a científicos de todo el mundo y ya se habla de una posible “revolución verde” en el campo de la energía renovable.\n",
    "La planta, bautizada popularmente como Electra Verde, fue detectada por primera vez cuando uno de los pastores notó que su viejo móvil, sin batería desde hacía días, se encendió al quedarse apoyado accidentalmente sobre la raíz expuesta de la planta. “Pensé que era cosa de meigas”, declaró entre risas. Pero al repetir el fenómeno varias veces, decidió contactar con expertos de la Universidad de Santiago.\n",
    "Aunque todavía no se ha confirmado nada oficialmente, filtraciones desde el laboratorio apuntan a que Electra Verde podría contener una combinación única de minerales y microalgas que generan corriente eléctrica mediante procesos aún no comprendidos por la ciencia.\n",
    "Mientras tanto, turistas y curiosos ya se agolpan en los montes gallegos, en busca de esta nueva joya botánica que podría hacer obsoletos los cargadores eléctricos en menos de una década.\n",
    "\"\"\"\n",
    "result = clf(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"modelo_fake_news\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1505331993103027, 'eval_model_preparation_time': 0.0015, 'eval_accuracy': 0.515, 'eval_f1': 0.44045455856479476, 'eval_runtime': 2.899, 'eval_samples_per_second': 68.99, 'eval_steps_per_second': 4.484}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=16,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arreglar dataset sintético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"verdades.csv\"\n",
    "output_file = \"verdades_fixed.csv\"\n",
    "title = True\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        if title:\n",
    "            title = False\n",
    "            continue\n",
    "        parts = line.split(\";\", 1)  # divide solo en las dos primeras comas\n",
    "        if len(parts) == 2:\n",
    "            nueva_linea = \"verdadero;\" + parts[1].replace(';',':')\n",
    "        else:\n",
    "            nueva_linea = line  # por si acaso no hay dos comas\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"falsedades.csv\"\n",
    "output_file = \"falsedades_fixed.csv\"\n",
    "title = True\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        if title:\n",
    "            title = False\n",
    "            continue\n",
    "        parts = line.split(\";\", 1)  # divide solo en las dos primeras comas\n",
    "        if len(parts) == 2:\n",
    "            nueva_linea = \"falso;\" + parts[1].replace(';',':')\n",
    "        else:\n",
    "            nueva_linea = line  # por si acaso no hay dos comas\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"falsedades_fixed.csv\",sep=';')\n",
    "dfv = pd.read_csv(\"verdades_fixed.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([dfv,dff],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('news.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar dataset sintético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'verdadero':'True','falso':'False'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\"text-classification\", model=\"../API/modelo_fake_news\", tokenizer=\"../API/modelo_fake_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo semántico es 0.6025641025641025\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for index,row in df.iterrows():\n",
    "    text = row['text']\n",
    "    if (len(row['text']) > 512):\n",
    "        text = text[:512]\n",
    "    result = clf(text)\n",
    "    if result[0]['label'] == row['label']:\n",
    "        accuracy += 1 \n",
    "print(f\"La precisión del modelo semántico es {accuracy/df.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
