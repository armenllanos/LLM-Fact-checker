{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busacador de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from os import path\n",
    "from pathlib import PurePath\n",
    "import concurrent.futures\n",
    "from transformers import pipeline\n",
    "from mistralai import Mistral\n",
    "import pandas as pd\n",
    "import accelerate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import base64\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "from google import genai\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from google.genai import types\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noticia:\n",
    "    def __init__(self, titular: str, url: str, resumen: str):\n",
    "\n",
    "        self.titular = titular\n",
    "        self.url = url\n",
    "        self.resumen = resumen\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracci√≥n de palabras clave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extraer_keywords_yake(texto, idioma=\"es\", max_keywords=5):\n",
    "    extractor = yake.KeywordExtractor(lan=idioma, n=1, top=max_keywords)\n",
    "    keywords = extractor.extract_keywords(texto)\n",
    "    display(keywords)\n",
    "    return [kw for kw, score in keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√∫squeda de noticias en base a las palabras clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_en_theobjective(keywords, max_noticias=5):\n",
    "    query = \"site:theobjective.com \" + \" \".join(keywords)\n",
    "    url = f\"https://html.duckduckgo.com/html/?q={query}\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    resultados = []\n",
    "    print(soup.prettify())\n",
    "    for result in soup.select(\"serp__results\"):\n",
    "        titulo_tag = result.select_one(\"result__title\")\n",
    "        enlace_tag = result.select_one(\"result__a\")\n",
    "        snippet_tag = result.select_one(\"result__snippet\")\n",
    "        \n",
    "        if not (titulo_tag and enlace_tag):\n",
    "            continue\n",
    "\n",
    "        titulo = titulo_tag.text.strip()\n",
    "        enlace = enlace_tag.get(\"href\")\n",
    "        resumen = snippet_tag.text.strip() if snippet_tag else \"\"\n",
    "        \n",
    "        resultados.append({\n",
    "            \"titulo\": titulo,\n",
    "            \"enlace\": enlace,\n",
    "            \"resumen\": resumen\n",
    "        })\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_en_theobjective_ddg(keywords, max_noticias=10):\n",
    "    query = \"site:theobjective.com \" + \" \".join(keywords)\n",
    "    resultados = []\n",
    "    print(query)\n",
    "    with DDGS() as ddgs:\n",
    "        for r in ddgs.text(query, max_results=max_noticias):\n",
    "            resultados.append({\n",
    "                \"titulo\": r[\"title\"],\n",
    "                \"enlace\": r[\"href\"],\n",
    "                \"resumen\": r[\"body\"]\n",
    "            })\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar(keywords):\n",
    "    query = \"site:theobjective.com \" + \" \".join(keywords)\n",
    "    url = f\"https://www.bing.com/search?q={query}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    print(f\"Busqueda en: {url}\")\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    resultados = []\n",
    "    \n",
    "    titulos = soup.find_all('h2')\n",
    "    resumenes = soup.find_all(class_='b_caption')\n",
    "    urls = []\n",
    "    for i in range(0,len(titulos)):\n",
    "        url = titulos[i].find('a')['href']\n",
    "        urls.append(url)\n",
    "    return urls\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_titular_y_resumen(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Estos selectores dependen de la estructura del sitio\n",
    "        titulo = soup.find('h1')\n",
    "        resumen = soup.find('p')\n",
    "\n",
    "        return {\n",
    "            'url': url,\n",
    "            'titulo': titulo.get_text(strip=True) if titulo else 'No encontrado',\n",
    "            'resumen': resumen.get_text(strip=True) if resumen else 'No encontrado',\n",
    "            'contenido':response.text\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'url': url,\n",
    "            'error': str(e)\n",
    "        }\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', np.float64(0.1447773057422032)),\n",
       " ('Donald', np.float64(0.15831692877998726)),\n",
       " ('moviles', np.float64(0.15831692877998726)),\n",
       " ('bajar', np.float64(0.29736558256021506)),\n",
       " ('precio', np.float64(0.29736558256021506))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busqueda en: https://www.bing.com/search?q=site:theobjective.com Trump Donald moviles bajar precio\n",
      "\n",
      "Mejores noticias por similitud\n",
      "\n",
      "Nota 0.7006726861000061\n",
      "\n",
      "T√≠tulo: Trump defiende sus aranceles y acusa a otros pa√≠ses de ¬´estafar¬ª a EEUU durante d√©cadas\n",
      "\n",
      "Nota 0.6497557759284973\n",
      "\n",
      "T√≠tulo: Donald Trump dobla la apuesta: 'made in USA' y¬†la amenaza de m√°s aranceles\n",
      "\n",
      "Nota 0.643012285232544\n",
      "\n",
      "T√≠tulo: Trump usa la econom√≠a como los borrachos las farolas: para abrazarse, no para iluminarse\n",
      "\n",
      "Nota 0.5764147043228149\n",
      "\n",
      "T√≠tulo: Trump sugiere que una bajada en el precio del petr√≥leo terminar√≠a con la guerra en Ucrania\n",
      "\n",
      "Nota 0.48289865255355835\n",
      "\n",
      "T√≠tulo: El Ibex 35 pierde los 13.100 puntos lastrado por los nuevos aranceles de Donald Trump\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Donald Trump va a bajar el precio de los moviles'\n",
    "keywords = extraer_keywords_yake(user_input)\n",
    "urls = buscar(keywords)\n",
    "\n",
    "resultados = {}\n",
    "for url in urls:\n",
    "    resultados[url] = extraer_titular_y_resumen(url) \n",
    "\n",
    "modelo = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "user_embeddings = modelo.encode([user_input])[0]\n",
    "mejores_noticias = {}\n",
    "for r in resultados.values():\n",
    "    title_embedding = modelo.encode([r['titulo']])[0]\n",
    "    subtitle_embedding = modelo.encode([r['resumen']])[0]\n",
    "    title_score = cosine_similarity([user_embeddings], [title_embedding])[0][0]\n",
    "    subtitle_score = cosine_similarity([user_embeddings], [subtitle_embedding])[0][0]\n",
    "    mean_score = title_score+subtitle_score/2\n",
    "    mejores_noticias[mean_score] = r['url']\n",
    "\n",
    "\n",
    "valoraciones_resumen = sorted(mejores_noticias.keys(),reverse=True)\n",
    "print(\"\\nMejores noticias por similitud\")\n",
    "for i in range(0,5):\n",
    "    print(f\"\\nNota {valoraciones_resumen[i]}\")\n",
    "    url = mejores_noticias[valoraciones_resumen[i]]\n",
    "    print(\"\\nT√≠tulo:\", resultados[url]['titulo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El presidente de\n",
      "Estados Unidos\n",
      ",\n",
      "Donald Trump\n",
      ", ha vuelto a sacar pecho de su pol√≠tica comercial asegurando que los nuevos\n",
      "aranceles\n",
      "anunciados por su Administraci√≥n son m√°s ¬´generosos¬ª que los que han aplicado durante a√±os otros pa√≠ses contra Washington. Lo ha hecho desde el avi√≥n presidencial, en unas declaraciones recogidas por\n",
      "Europa Press\n",
      ", en las que ha insistido en que su Gobierno no est√° haciendo otra cosa que corregir d√©cadas de desventajas.\n",
      "¬´Los aranceles son mucho m√°s generosos de lo que esos pa√≠ses han sido con nosotros¬ª\n",
      ", defendi√≥ Trump a bordo del\n",
      "Air Force One\n",
      ". ¬´Lo que significa ‚Äîa√±adi√≥‚Äî que ser√°n m√°s amables de lo que esos pa√≠ses han sido con Estados Unidos durante d√©cadas¬ª.\n",
      "El mandatario estadounidense, que ha hecho de\n",
      "la pol√≠tica proteccionista una de sus banderas desde que regres√≥ a la Casa Blanca\n",
      ", arremeti√≥ con dureza contra las potencias que mantienen relaciones comerciales con EEUU. ¬´Nos han estafado como nunca se ha estafado a ning√∫n pa√≠s en la historia, y vamos a ser mucho m√°s amables de lo que ellos fueron con nosotros¬ª, subray√≥, si bien remarc√≥ que ¬´a pesar de todo, es un dinero sustancial para el pa√≠s¬ª.\n",
      "Trump, harto de Putin: amenaza con aranceles ¬´a todo el petr√≥leo que salga de Rusia¬ª\n",
      "THE OBJECTIVE\n",
      "De esta forma, Trump mantiene su pulso arancelario pese a las advertencias de grandes fabricantes, especialmente del sector del autom√≥vil, sobre el impacto que podr√≠an tener esas medidas en el consumidor estadounidense.\n",
      "Sin ir m√°s lejos, este s√°bado asegur√≥ en una entrevista con la cadena\n",
      "NBC News\n",
      "que\n",
      "no le preocupa ¬´lo m√°s m√≠nimo¬ª que las automovil√≠sticas suban los precios como consecuencia directa de los aranceles del 25% anunciados para los veh√≠culos importados\n",
      ". ¬´No me importa¬ª, zanj√≥.\n",
      "Espa√±a, uno de los pa√≠ses m√°s afectados por los aranceles de Trump al petr√≥leo venezolano\n",
      "V√≠ctor Recacha\n",
      "El nuevo giro proteccionista del presidente republicano reaviva la tensi√≥n en plena carrera electoral y anticipa un nuevo episodio en la guerra comercial que √©l mismo reactiv√≥ desde su retorno al Despacho Oval.\n"
     ]
    }
   ],
   "source": [
    "clase_noticia = 'div.tno-general-single__article__main__content.tno-single-content'\n",
    "noticia =  resultados[mejores_noticias[valoraciones_resumen[0]]]['contenido']\n",
    "soup = BeautifulSoup(noticia, 'html.parser')\n",
    "# print(soup)\n",
    "contenedor = soup.select_one(clase_noticia)\n",
    "contenido = contenedor.get_text(separator='\\n', strip=True) if contenedor else 'No encontrado'\n",
    "\n",
    "print(contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generaci√≥n de embeddings del input del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', np.float64(0.1447773057422032)),\n",
       " ('Donald', np.float64(0.15831692877998726)),\n",
       " ('moviles', np.float64(0.15831692877998726)),\n",
       " ('bajar', np.float64(0.29736558256021506)),\n",
       " ('precio', np.float64(0.29736558256021506))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site:theobjective.com Trump Donald moviles bajar precio\n",
      "Mejores noticias por similitud con el titular\n",
      "\n",
      "T√≠tulo: Espa√±a hace gui√±os a los fabricantes chinos de m√≥viles en plena ...\n",
      "Enlace: https://theobjective.com/economia/telecomunicaciones/2025-03-05/espana-fabricantes-chinos-mobile-eeuu/\n",
      "Resumen: El posicionamiento del Gobierno espa√±ol frente a China cobra mucha m√°s importancia ahora que Estados Unidos amenaza con elevados aranceles a Europa y que Donald Trump ha incluido al bloque...\n",
      "\n",
      "T√≠tulo: Espa√±a se juega 46.000 millones de euros tras la √∫ltima amenaza de ...\n",
      "Enlace: https://theobjective.com/economia/2025-03-31/trump-46000-millones-espana-aranceles/\n",
      "Resumen: El Ibex 35 pierde los 13.100 puntos lastrado por los nuevos aranceles de Donald Trump\n",
      "\n",
      "Mejores noticias por similitud con el resumen\n",
      "\n",
      "T√≠tulo: Las consecuencias econ√≥micas de Trump para Espa√±a - THE OBJECTIVE\n",
      "Enlace: https://theobjective.com/economia/2025-02-11/gris-importa-consecuencias-trump-economia-espanola/\n",
      "Resumen: Los n√∫meros de la econom√≠a espa√±ola son razonablemente buenos. Se mantiene el vigor de la actividad, con un aumento del PIB del 3,2% en 2024. Este buen 'El Gris Importa' analiza el impacto de las...\n",
      "\n",
      "T√≠tulo: El Ibex 35 pierde los 13.100 puntos lastrado por los nuevos aranceles ...\n",
      "Enlace: https://theobjective.com/economia/2025-03-31/ibex-35-aranceles-donald-trump/\n",
      "Resumen: El Ibex 35 ha perdido este lunes los 13.200 puntos en una jornada marcada por la inquietud de los inversores tras el anuncio del expresidente de Estados Unidos, Donald Trump, sobre nuevos...\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Donald Trump va a bajar el precio de los moviles'\n",
    "modelo = SentenceTransformer('jinaai/jina-embeddings-v3')\n",
    "user_embeddings = modelo.encode([user_input])[0]\n",
    "keywords = extraer_keywords_yake(user_input)\n",
    "\n",
    "\n",
    "#noticias = buscar_en_theobjective(keywords)\n",
    "noticias = buscar_en_theobjective_ddg(keywords)\n",
    "mejores_noticias_titular = {}\n",
    "mejores_noticias_resumen = {}\n",
    "\n",
    "for noticia in noticias:\n",
    "    new_noticia = Noticia(noticia[\"titulo\"],noticia[\"enlace\"],noticia[\"resumen\"])\n",
    "    sentence_embeddings = modelo.encode([noticia[\"titulo\"]])[0]\n",
    "    sim_coseno = cosine_similarity([user_embeddings], [sentence_embeddings])[0][0]\n",
    "    mejores_noticias_titular[sim_coseno] = new_noticia\n",
    "    \n",
    "    sentence_embeddings = modelo.encode([noticia[\"resumen\"]])[0]\n",
    "    sim_coseno = cosine_similarity([user_embeddings], [sentence_embeddings])[0][0]\n",
    "    mejores_noticias_resumen[sim_coseno] = new_noticia\n",
    "\n",
    "valoraciones_titular = sorted(mejores_noticias_titular.keys())\n",
    "print(\"Mejores noticias por similitud con el titular\")\n",
    "for i in range(0,2):\n",
    "    print(\"\\nT√≠tulo:\", mejores_noticias_titular[valoraciones_titular[i]].titular)\n",
    "    print(\"Enlace:\", mejores_noticias_titular[valoraciones_titular[i]].url)\n",
    "    print(\"Resumen:\", mejores_noticias_titular[valoraciones_titular[i]].resumen)\n",
    "\n",
    "valoraciones_resumen = sorted(mejores_noticias_resumen.keys())\n",
    "print(\"\\nMejores noticias por similitud con el resumen\")\n",
    "for i in range(0,2):\n",
    "    print(\"\\nT√≠tulo:\", mejores_noticias_resumen[valoraciones_resumen[i]].titular)\n",
    "    print(\"Enlace:\", mejores_noticias_resumen[valoraciones_resumen[i]].url)\n",
    "    print(\"Resumen:\", mejores_noticias_resumen[valoraciones_resumen[i]].resumen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llamada al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Eres un analista de informaci√≥n riguroso. El usuario te enviar√° un mensaje con DOS textos separados:  \n",
    "1. El primero es una afirmaci√≥n o interpretaci√≥n sobre una noticia.  \n",
    "2. El segundo es la noticia completa (o un fragmento relevante).  \n",
    "\n",
    "Tu tarea es:  \n",
    "1. Comparar la afirmaci√≥n (texto 1) con el contenido de la noticia (texto 2).  \n",
    "2. Decidir si la afirmaci√≥n es:  \n",
    "   - **‚úÖ CIERTA**: Si la noticia respalda claramente la afirmaci√≥n.  \n",
    "   - **‚ùå FALSA**: Si la noticia contradice directamente la afirmaci√≥n.  \n",
    "   - **üîé NO VERIFICABLE**: Si la noticia no contiene informaci√≥n suficiente para validar o refutar la afirmaci√≥n.  \n",
    "\n",
    "Responde √öNICAMENTE con una de las 3 opciones (‚úÖ CIERTA, ‚ùå FALSA, üîé NO VERIFICABLE) y a√±ade una explicaci√≥n breve en la misma l√≠nea.  \n",
    "Mant√©n un tono neutral y objetivo.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"\"\"[Afirmaci√≥n] :  \"\"\" + user_input +\"\"\" [Noticia]: \"\"\" + contenido\n",
    "messages = [\n",
    "        {   \n",
    "            \"role\":\"system\",\"content\":system_message},\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": user_message\n",
    "        }\n",
    "    ]\n",
    "input_text = f\"<|system|>\\n{system_message}\\n<|user|>\\n{user_message}\\n<|assistant|>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de hugging face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`rope_scaling`'s factor field must be a float >= 1, got 40\n",
      "`rope_scaling`'s beta_fast field must be a float, got 32\n",
      "`rope_scaling`'s beta_slow field must be a float, got 1\n",
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-V3-Base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-V3-Base\"  # o \"deepseek-ai/deepseek-coder-6.7b\" para c√≥digo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",  # Usa GPU autom√°ticamente\n",
    "    torch_dtype=torch.float16  # Reduce uso de memoria (opcional)\n",
    ")\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.3 \n",
    ")\n",
    "\n",
    "respuesta = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(respuesta.split(\"<|assistant|>\")[-1].strip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded an FP8 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-R1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1\", trust_remote_code=True)\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo por API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"sk-d80c8a131e6f464aae72ddc7b48f10b6\"\n",
    "url = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"deepseek-chat\",  # Revisa los modelos disponibles en la documentaci√≥n\n",
    "    \"messages\":messages\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probar Gemini\n",
    "https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internacional\n",
      "None"
     ]
    }
   ],
   "source": [
    "client = genai.Client(\n",
    "    api_key=\"AIzaSyCaPiJUBW1V2eJ5YUZgJD_RF0R9knWiR2Q\",\n",
    ")\n",
    "\n",
    "model = \"gemma-3-27b-it\"\n",
    "contents = [\n",
    "    types.Content(\n",
    "        role=\"model\",\n",
    "        parts=[\n",
    "            types.Part.from_text(text=\"\"\"Analiza el siguiente texto y determina si trata sobre un tema de √≠ndole nacional (relacionado con Espa√±a) o internacional. Ten en cuenta el contexto, los lugares, instituciones, personajes o eventos mencionados. Devuelve √∫nicamente una de estas dos etiquetas: 'Nacional' o 'Internacional'.\"\"\"),\n",
    "        ],\n",
    "    ),\n",
    "    types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            types.Part.from_text(text=\"\"\"Donald trump se acuesta con putin\"\"\"),\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    max_output_tokens=2000,\n",
    "    response_mime_type=\"text/plain\",\n",
    ")\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=model,\n",
    "    contents=contents,\n",
    "    config=generate_content_config,\n",
    "):\n",
    "    print(chunk.text, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nacional\n"
     ]
    }
   ],
   "source": [
    "api_key = \"uncjhLuimnWfA7S3QJrw7iTWsjYgd2tj\"\n",
    "model = \"mistral-large-latest\"\n",
    "system_promt = \"Analiza el siguiente texto y determina si trata sobre un tema de √≠ndole nacional (relacionado con Espa√±a) o internacional. Ten en cuenta el contexto, los lugares, instituciones, personajes o eventos mencionados. Devuelve √∫nicamente una de estas dos etiquetas: 'Nacional' o 'Internacional'.\"\n",
    "user_prompt =\"El real madrid ha asesinado a vinicius.jr\"\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "chat_response = client.chat.complete(\n",
    "    model= model,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_promt,\n",
    "    },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba modelos distintos prop√≥sitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisor de afirmaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-V3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-V3:\n",
      "- configuration_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-V3:\n",
      "- modeling_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "You have loaded an FP8 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear pipeline con un modelo instructivo\n",
    "generator = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-V3\",trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-V3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You have loaded an FP8 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "Fetching 163 files:   0%|          | 0/163 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-V3\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-V3\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Texto de entrada\n",
    "text = \"\"\"\n",
    "La inteligencia artificial est√° transformando el mundo. Se usa en medicina, educaci√≥n, transporte y finanzas.\n",
    "Tambi√©n plantea desaf√≠os √©ticos como el sesgo y la p√©rdida de empleos.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt para dividir en afirmaciones\n",
    "prompt = f\"Divide el siguiente texto en afirmaciones claras, una por l√≠nea:\\n\\n{text}\\n\\nAfirmaciones:\"\n",
    "\n",
    "# Generar resultado\n",
    "result = generator(prompt, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "# Mostrar salida\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificaci√≥n nacional/internacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Texto de entrada\n",
    "text = \"\"\"\n",
    "La inteligencia artificial est√° transformando el mundo. Se usa en medicina, educaci√≥n, transporte y finanzas.\n",
    "Tambi√©n plantea desaf√≠os √©ticos como el sesgo y la p√©rdida de empleos.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt para dividir en afirmaciones\n",
    "prompt = f\"Divide el siguiente texto en afirmaciones claras, una por l√≠nea:\\n\\n{text}\\n\\nAfirmaciones:\"\n",
    "\n",
    "# Generar resultado\n",
    "result = generator(prompt, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "# Mostrar salida\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcci√≥n de dataset texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_excel = \"./FakeNewsDetectorSpanish/train.xlsx\"\n",
    "\n",
    "# Leer el archivo Excel\n",
    "df1 = pd.read_excel(ruta_excel)\n",
    "\n",
    "# Verificar que las columnas existen\n",
    "if 'Text' not in df1.columns or 'Category' not in df1.columns:\n",
    "    raise ValueError(\"El archivo debe contener las columnas 'text' y 'category'.\")\n",
    "\n",
    "# Crear el dataset solo con las columnas deseadas\n",
    "df1 = df1[['Text', 'Category']].copy()\n",
    "df1['label'] = df1['Category'].map({'True': 0, 'Fake': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_csv = \"./archive/spanishFakeNews.csv\"\n",
    "df2 = pd.read_csv(ruta_csv)\n",
    "\n",
    "df2.rename(columns={'texto':'Text','clase':'Category'}, inplace=True)\n",
    "df2['label'] = df2['Category'].map({'real': 0, 'fake': 1})\n",
    "ruta_csv = \"./archive/testSpanishFakeNews.csv\"\n",
    "df3 = pd.read_csv(ruta_csv)\n",
    "\n",
    "df3.rename(columns={'texto':'Text','clase':'Category'}, inplace=True)\n",
    "df3['label'] = df2['Category'].map({'real': 0, 'fake': 1})\n",
    "df2 = pd.concat([df2,df3],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset con noticias traducidas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"translated_news_8.csv\"\n",
    "output_file = \"translated_news_mod.csv\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        parts = line.split(\",\", 2)  # divide solo en las dos primeras comas\n",
    "        if len(parts) == 3:\n",
    "            nueva_linea = parts[0] + \";\" + parts[1] + \";\" + parts[2]\n",
    "        else:\n",
    "            nueva_linea = line  # por si acaso no hay dos comas\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"translated_news_mod.csv\"\n",
    "output_file = \"translated_news_8.csv\"\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        partes = line.split(\";\")\n",
    "        if len(partes) > 2:\n",
    "            # Conserva los dos primeros campos con ;\n",
    "            primeros_dos = partes[:2]\n",
    "            resto = partes[2:]\n",
    "            # Une los campos restantes con comas\n",
    "            nueva_linea = \";\".join(primeros_dos) + \";\" + \",\".join(resto)\n",
    "        else:\n",
    "            # Si no hay m√°s de dos campos separados por ;, no se modifica\n",
    "            nueva_linea = line\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('translated_news.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.concat([df,pd.read_csv('translated_news_1.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_2.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_3.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_4.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_5.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_6.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_7.csv',sep=';')],ignore_index=True)\n",
    "df = pd.concat([df,pd.read_csv('translated_news_8.csv',sep=';')],ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LONDRES (Reuters) - Los legisladores brit√°nico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EDINBURGH (Reuters) - Un acuerdo para mantener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17 de noviembre de 2016 - Fort Russ - Antifash...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label Category                                               Text\n",
       "0      0        0  LONDRES (Reuters) - Los legisladores brit√°nico...\n",
       "1      0        0  EDINBURGH (Reuters) - Un acuerdo para mantener...\n",
       "2      1        1  17 de noviembre de 2016 - Fort Russ - Antifash..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)\n",
    "df.rename(columns={'Text':'label','label':'Text'},inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarte de que category es de tipo str o int\n",
    "df['Category'] = df['Category'].astype(str)\n",
    "df['label'] = df['label'].astype(int)\n",
    "df.dropna(inplace=True)\n",
    "# Convertir a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 1931.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'verdadero': 0, 'falso': 1})\n",
    "df['label'] = df['label'].astype(int)\n",
    "df.dropna(inplace=True)\n",
    "# Convertir a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)\n",
    "modelo_nombre = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_nombre)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = tokenized_dataset['label']\n",
    "label_encoder.fit(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1274/1274 [00:01<00:00, 998.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "modelo_nombre = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_nombre)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "all_labels = tokenized_dataset['label']\n",
    "label_encoder.fit(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1019/1019 [00:00<00:00, 8623.88 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 255/255 [00:00<00:00, 7992.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)  # opcional\n",
    "\n",
    "# Ajustar sobre todo el dataset\n",
    "all_labels = tokenized_dataset['train']['Category'] + tokenized_dataset['test']['Category']\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Aplicar a cada parte\n",
    "tokenized_dataset = tokenized_dataset.map(lambda x: {\"label\": label_encoder.transform([x[\"Category\"]])[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traducci√≥n de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\",device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./fake_en_dataset/WELFake_Dataset.csv\")  # o el dataset que tengas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'es: mi nombre es miguel'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator('my name is Miguel',src_lang='en',tgt_lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (512). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 1 is bigger than 0.9 * max_length: 1. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    }
   ],
   "source": [
    "columnas = ['Text', 'Category', 'label']\n",
    "df_es = pd.DataFrame(columns=columnas)\n",
    "\n",
    "# Traduce por lotes de 10 (recomendado para no saturar la RAM)\n",
    "translated = []\n",
    "with open('translated_news.csv', 'w', encoding='utf-8') as f:\n",
    "    # Escribir la cabecera\n",
    "    f.write(','.join(df_es.columns) + '\\n')\n",
    "f.close()\n",
    "fieldnames = ['Category','label','Text']\n",
    "for index,new in df.iterrows():\n",
    "    try:\n",
    "        results = translator(new['text'], max_length=len(new['text']),src_lang='en',tgt_lang='es')\n",
    "    except:\n",
    "        continue\n",
    "    linea = str(new['label']) + ',' +  str(new['label']) +','+ str(results[0]['translation_text']).replace('es:','')\n",
    "    with open('translated_news.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        csvfile.write(linea + '\\n')\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de an√°lisis sem√°ntico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n de modelo para elecci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* VerificadoProfesional/SaBERT-Spanish-Fake-News\n",
    "* Narrativaai/fake-news-detection-spanish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'Category', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1274\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "nombre = \"Narrativaai/fake-news-detection-spanish\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"modelo_fake_news\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nombre, num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.997157096862793, 'eval_model_preparation_time': 0.0014, 'eval_accuracy': 0.5400313971742543, 'eval_f1': 0.528402773285684, 'eval_runtime': 15.2014, 'eval_samples_per_second': 83.808, 'eval_steps_per_second': 5.263}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=16,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrl\\AppData\\Local\\anaconda3\\envs\\TFM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\mrl\\AppData\\Local\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mrl\\.cache\\huggingface\\hub\\models--VerificadoProfesional--SaBERT-Spanish-Fake-News. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"VerificadoProfesional/SaBERT-Spanish-Fake-News\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrl\\AppData\\Local\\anaconda3\\envs\\TFM\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mrl\\.cache\\huggingface\\hub\\models--Narrativaai--fake-news-detection-spanish. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"Narrativaai/fake-news-detection-spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"modelo_fake_news\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Un grupo de pastores gallegos ha descubierto en los montes de Lugo una extra√±a planta aut√≥ctona que, seg√∫n aseguran, puede cargar tel√©fonos m√≥viles con solo entrar en contacto con ellos. El hallazgo ha revolucionado a cient√≠ficos de todo el mundo y ya se habla de una posible ‚Äúrevoluci√≥n verde‚Äù en el campo de la energ√≠a renovable.\n",
    "La planta, bautizada popularmente como Electra Verde, fue detectada por primera vez cuando uno de los pastores not√≥ que su viejo m√≥vil, sin bater√≠a desde hac√≠a d√≠as, se encendi√≥ al quedarse apoyado accidentalmente sobre la ra√≠z expuesta de la planta. ‚ÄúPens√© que era cosa de meigas‚Äù, declar√≥ entre risas. Pero al repetir el fen√≥meno varias veces, decidi√≥ contactar con expertos de la Universidad de Santiago.\n",
    "Aunque todav√≠a no se ha confirmado nada oficialmente, filtraciones desde el laboratorio apuntan a que Electra Verde podr√≠a contener una combinaci√≥n √∫nica de minerales y microalgas que generan corriente el√©ctrica mediante procesos a√∫n no comprendidos por la ciencia.\n",
    "Mientras tanto, turistas y curiosos ya se agolpan en los montes gallegos, en busca de esta nueva joya bot√°nica que podr√≠a hacer obsoletos los cargadores el√©ctricos en menos de una d√©cada.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'FAKE', 'score': 0.999971866607666}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning modelo ling√º√≠stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"VerificadoProfesional/SaBERT-Spanish-Fake-News\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modelo, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27348\\1752722915.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7089' max='7089' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7089/7089 1:13:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.127817</td>\n",
       "      <td>0.967305</td>\n",
       "      <td>0.967268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.136887</td>\n",
       "      <td>0.968363</td>\n",
       "      <td>0.968404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.983388</td>\n",
       "      <td>0.983382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7089, training_loss=0.10595419522903525, metrics={'train_runtime': 4425.3995, 'train_samples_per_second': 25.625, 'train_steps_per_second': 1.602, 'total_flos': 2.983758301099008e+16, 'train_loss': 0.10595419522903525, 'epoch': 3.0})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='591' max='591' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [591/591 01:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0846896693110466,\n",
       " 'eval_accuracy': 0.9833880012697069,\n",
       " 'eval_f1': 0.9833821828938577,\n",
       " 'eval_runtime': 109.8881,\n",
       " 'eval_samples_per_second': 86.006,\n",
       " 'eval_steps_per_second': 5.378,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('modelo_fake_news\\\\tokenizer_config.json',\n",
       " 'modelo_fake_news\\\\special_tokens_map.json',\n",
       " 'modelo_fake_news\\\\vocab.txt',\n",
       " 'modelo_fake_news\\\\added_tokens.json',\n",
       " 'modelo_fake_news\\\\tokenizer.json')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"modelo_fake_news\")\n",
    "tokenizer.save_pretrained(\"modelo_fake_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\"text-classification\", model=\"modelo_fake_news\", tokenizer=\"modelo_fake_news\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'False', 'score': 0.9900426864624023}]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Un grupo de pastores gallegos ha descubierto en los montes de Lugo una extra√±a planta aut√≥ctona que, seg√∫n aseguran, puede cargar tel√©fonos m√≥viles con solo entrar en contacto con ellos. El hallazgo ha revolucionado a cient√≠ficos de todo el mundo y ya se habla de una posible ‚Äúrevoluci√≥n verde‚Äù en el campo de la energ√≠a renovable.\n",
    "La planta, bautizada popularmente como Electra Verde, fue detectada por primera vez cuando uno de los pastores not√≥ que su viejo m√≥vil, sin bater√≠a desde hac√≠a d√≠as, se encendi√≥ al quedarse apoyado accidentalmente sobre la ra√≠z expuesta de la planta. ‚ÄúPens√© que era cosa de meigas‚Äù, declar√≥ entre risas. Pero al repetir el fen√≥meno varias veces, decidi√≥ contactar con expertos de la Universidad de Santiago.\n",
    "Aunque todav√≠a no se ha confirmado nada oficialmente, filtraciones desde el laboratorio apuntan a que Electra Verde podr√≠a contener una combinaci√≥n √∫nica de minerales y microalgas que generan corriente el√©ctrica mediante procesos a√∫n no comprendidos por la ciencia.\n",
    "Mientras tanto, turistas y curiosos ya se agolpan en los montes gallegos, en busca de esta nueva joya bot√°nica que podr√≠a hacer obsoletos los cargadores el√©ctricos en menos de una d√©cada.\n",
    "\"\"\"\n",
    "result = clf(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"modelo_fake_news\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1505331993103027, 'eval_model_preparation_time': 0.0015, 'eval_accuracy': 0.515, 'eval_f1': 0.44045455856479476, 'eval_runtime': 2.899, 'eval_samples_per_second': 68.99, 'eval_steps_per_second': 4.484}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=16,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arreglar dataset sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"verdades.csv\"\n",
    "output_file = \"verdades_fixed.csv\"\n",
    "title = True\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        if title:\n",
    "            title = False\n",
    "            continue\n",
    "        parts = line.split(\";\", 1)  # divide solo en las dos primeras comas\n",
    "        if len(parts) == 2:\n",
    "            nueva_linea = \"verdadero;\" + parts[1].replace(';',':')\n",
    "        else:\n",
    "            nueva_linea = line  # por si acaso no hay dos comas\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"falsedades.csv\"\n",
    "output_file = \"falsedades_fixed.csv\"\n",
    "title = True\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        if title:\n",
    "            title = False\n",
    "            continue\n",
    "        parts = line.split(\";\", 1)  # divide solo en las dos primeras comas\n",
    "        if len(parts) == 2:\n",
    "            nueva_linea = \"falso;\" + parts[1].replace(';',':')\n",
    "        else:\n",
    "            nueva_linea = line  # por si acaso no hay dos comas\n",
    "        outfile.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"falsedades_fixed.csv\",sep=';')\n",
    "dfv = pd.read_csv(\"verdades_fixed.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([dfv,dff],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('news.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar dataset sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'verdadero':'True','falso':'False'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\"text-classification\", model=\"../API/modelo_fake_news\", tokenizer=\"../API/modelo_fake_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisi√≥n del modelo sem√°ntico es 0.6025641025641025\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for index,row in df.iterrows():\n",
    "    text = row['text']\n",
    "    if (len(row['text']) > 512):\n",
    "        text = text[:512]\n",
    "    result = clf(text)\n",
    "    if result[0]['label'] == row['label']:\n",
    "        accuracy += 1 \n",
    "print(f\"La precisi√≥n del modelo sem√°ntico es {accuracy/df.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
